import sys
import numpy as np
import cv2
import random
import math
import os
import time
import zlib
import socket
import threading
import Queue
import sys
import cPickle as pickle
import h5py
import scipy.io as sio

BATCH_SIZE=32
POINTCLOUDSIZE=2048
GTPOINTS=100000
n_pc_points = 10240
bneck=128
latent_size=128
loss_type = "eac"  # cd emd eac
part_name = "AEpartc"
reg_alpha = 0.1
learning_rate = 3e-5
saver_step = 10
decay_steps =30000
exponential_decay=False


TV_SIZE=1095 #(all train + validating data set)
ALL_SIZE=1369 #all data set

class BatchFetcherAE(threading.Thread):
	def __init__(self, dataname,train_flag,all_size):
		super(BatchFetcherAE,self).__init__()
		self.queue=Queue.Queue(128)
		self.stopped=False
		self.datadir = dataname
		self.bno=0
		self.train=train_flag
		self.all_size=all_size
		
	def work(self,bno):
		'''
		path = os.path.join(self.datadir,'%d/%d'%(bno//1200,bno))
		if not os.path.exists(path):
			self.stopped=True
			print "error! data file not exists: %s"%path
			print "please KILL THIS PROGRAM otherwise it will bear undefined behaviors"
			assert False,"data file not exists: %s"%path
		mat_data = h5py.File(path)
		validating=mat_data['validating'][0]
		#gnoise = np.random.normal(mu, sigma, [BATCH_SIZE,NOISE_DIMENSION])
		mat_data.close()
		'''
		#ac_pc = sio.loadmat('../../multiple_pgt_point_2048/%d.mat'%(bno))
		ac_pc = sio.loadmat('../../ae_2048_points/%d.mat'%(bno))  
		data = ac_pc['pc']
		validating = ac_pc['validating']
		return (data,validating)
		
		#ac_pc = sio.loadmat('../normalize/pc_%d.mat'%(bno))
		#data = ac_pc['pc']
		#validating=ac_pc['validating']
		#return (data,validating)
		
	def run(self):
		while self.bno<self.all_size and not self.stopped:
			if self.train:#train
				self.queue.put(self.work(self.bno%TV_SIZE))
			else:#prediction
				self.queue.put(self.work(self.bno))
			self.bno+=1
	def fetch(self):
		if self.stopped:
			return None
		return self.queue.get()
	def shutdown(self):
		self.stopped=True
		while not self.queue.empty():
			self.queue.get()


